{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a sentiment analysis model.\n",
    "I am using a dataset of 1.6 million tweets found on Kaggle for the training dataset, its not strictly a data set that is made for stock sentiment analysis. There are some dataset that are restricted to stocks, I hypothesise that the same analysis will be applicable. I will test this by using these restricted datasets for validation. The dataset will not be in the repository as it is too large but I have included a link to it below. I have also drawn on on a medium tutorial on sentiment analysis in pytorch.\n",
    "\n",
    "The dataset: https://www.kaggle.com/datasets/kazanova/sentiment140?resource=download\n",
    "\n",
    "Medium Tutorial: https://bhadreshpsavani.medium.com/tutorial-on-sentimental-analysis-using-pytorch-b1431306a2d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import csv\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    " \n",
    "# for printing out status reports\n",
    "import sys\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# use GPU prioitising apple silicon then nvidia cuda and lastly cpu. \n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = getattr(torch,'has_mps',False)\n",
    "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                         Tweet_text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pull the data from the csv file, \n",
    "\n",
    "df = pd.read_csv('../Sentiment_Analysis_Strategy/training.1600000.processed.noemoticon.csv', header= None,encoding='latin-1' )\n",
    "\n",
    "# We dont need most of hte columns such as tweet author or the date and time. \n",
    "\n",
    "df.drop([1,2,3,4], inplace=True, axis=1)\n",
    "\n",
    "df.columns =['Sentiment','Tweet_text']\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used in the next cell to remove all of the special characters in th tweets\n",
    "\n",
    "def removespecial(tweet):\n",
    "    \n",
    "    #calling alpha because it is returning just the alphabet. \n",
    "    \n",
    "    alpha = \"\"\n",
    "    \n",
    "    for ch in tweet:\n",
    "        if ch not in punctuation:\n",
    "            alpha = alpha + ch\n",
    "            \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to remove the special characters from the tweets and we need to fix the words to remove caps etc. we could do this by looping through but it will just take far too long\n",
    "\n",
    "df['Tweet_text'] = df['Tweet_text'].apply(lambda x: x.lower())\n",
    "df['Tweet_text'] = df['Tweet_text'].apply(lambda x: removespecial(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                         Tweet_text\n",
       "0          0  switchfoot httptwitpiccom2y1zl  awww thats a b...\n",
       "1          0  is upset that he cant update his facebook by t...\n",
       "2          0  kenichan i dived many times for the ball manag...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  nationwideclass no its not behaving at all im ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that we have the tweets in a format we are looking for. \n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_words</th>\n",
       "      <th>Tweets_counted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>{'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>{'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>[kenichan, i, dived, many, times, for, the, ba...</td>\n",
       "      <td>{'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>{'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>{'nationwideclass': 1, 'no': 1, 'its': 1, 'not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>[just, woke, up, having, no, school, is, the, ...</td>\n",
       "      <td>{'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom  very cool to hear old walt intervie...</td>\n",
       "      <td>[thewdbcom, very, cool, to, hear, old, walt, i...</td>\n",
       "      <td>{'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>[are, you, ready, for, your, mojo, makeover, a...</td>\n",
       "      <td>{'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
       "      <td>[happy, 38th, birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>{'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
       "      <td>[happy, charitytuesday, thenspcc, sparkscharit...</td>\n",
       "      <td>{'happy': 1, 'charitytuesday': 1, 'thenspcc': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                         Tweet_text  \\\n",
       "0                0  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1                0  is upset that he cant update his facebook by t...   \n",
       "2                0  kenichan i dived many times for the ball manag...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  nationwideclass no its not behaving at all im ...   \n",
       "...            ...                                                ...   \n",
       "1599995          4  just woke up having no school is the best feel...   \n",
       "1599996          4  thewdbcom  very cool to hear old walt intervie...   \n",
       "1599997          4  are you ready for your mojo makeover ask me fo...   \n",
       "1599998          4  happy 38th birthday to my boo of alll time tup...   \n",
       "1599999          4  happy charitytuesday thenspcc sparkscharity sp...   \n",
       "\n",
       "                                               Tweet_words  \\\n",
       "0        [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1        [is, upset, that, he, cant, update, his, faceb...   \n",
       "2        [kenichan, i, dived, many, times, for, the, ba...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [nationwideclass, no, its, not, behaving, at, ...   \n",
       "...                                                    ...   \n",
       "1599995  [just, woke, up, having, no, school, is, the, ...   \n",
       "1599996  [thewdbcom, very, cool, to, hear, old, walt, i...   \n",
       "1599997  [are, you, ready, for, your, mojo, makeover, a...   \n",
       "1599998  [happy, 38th, birthday, to, my, boo, of, alll,...   \n",
       "1599999  [happy, charitytuesday, thenspcc, sparkscharit...   \n",
       "\n",
       "                                            Tweets_counted  \n",
       "0        {'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...  \n",
       "1        {'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...  \n",
       "2        {'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...  \n",
       "3        {'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...  \n",
       "4        {'nationwideclass': 1, 'no': 1, 'its': 1, 'not...  \n",
       "...                                                    ...  \n",
       "1599995  {'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...  \n",
       "1599996  {'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...  \n",
       "1599997  {'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...  \n",
       "1599998  {'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...  \n",
       "1599999  {'happy': 1, 'charitytuesday': 1, 'thenspcc': ...  \n",
       "\n",
       "[1600000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next we need to take all of the words in the tweets and count the occurrences of each word. this is done so we can enumerate the words.\n",
    "# We need to enumerate the words because our model later will need to take integers as its inputs. First we split the tweets into lists with all of the words\n",
    "df['Tweet_words'] = df['Tweet_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Next we need one super string that has all of the tweets as one string. This step can take a very long time. So we will do it by making the counter work over every entry then adding those instead.\n",
    "\n",
    "df['Tweets_counted'] = df['Tweet_words'].apply(lambda x: Counter(x))\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might seem like a slightly odd way to collect the text of all of the words, but this is a faster method compared to using sum over the text in all tweets\n",
    "# It will split the tweets into groups of 1000 and run Counter over them. Aprox 10 minuites\n",
    "collections = {}\n",
    "divisions = 1600\n",
    "for i in range(divisions):\n",
    "    collections[f\"{i}\"] = df['Tweets_counted'].iloc[int(len(df.index)/divisions * i) : int(len(df.index)/divisions * (i+1))].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then combining those 1600 collections into one large mega collection of all words and how often they appear. \n",
    "\n",
    "word_count = sum(collections.values(),Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting so the most common words are first\n",
    "\n",
    "sorted_words = word_count.most_common(len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerating the words in the list by how common they are.\n",
    "\n",
    "Enumerated_words ={w:i+1 for i,(w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'to': 2,\n",
       " 'the': 3,\n",
       " 'a': 4,\n",
       " 'my': 5,\n",
       " 'and': 6,\n",
       " 'you': 7,\n",
       " 'is': 8,\n",
       " 'it': 9,\n",
       " 'for': 10,\n",
       " 'in': 11,\n",
       " 'of': 12,\n",
       " 'im': 13,\n",
       " 'on': 14,\n",
       " 'me': 15,\n",
       " 'so': 16,\n",
       " 'have': 17,\n",
       " 'that': 18,\n",
       " 'but': 19,\n",
       " 'just': 20,\n",
       " 'with': 21,\n",
       " 'be': 22,\n",
       " 'at': 23,\n",
       " 'its': 24,\n",
       " 'not': 25,\n",
       " 'was': 26,\n",
       " 'this': 27,\n",
       " 'now': 28,\n",
       " 'good': 29,\n",
       " 'up': 30,\n",
       " 'day': 31,\n",
       " 'get': 32,\n",
       " 'all': 33,\n",
       " 'out': 34,\n",
       " 'like': 35,\n",
       " 'are': 36,\n",
       " 'no': 37,\n",
       " 'go': 38,\n",
       " 'dont': 39,\n",
       " 'do': 40,\n",
       " 'your': 41,\n",
       " 'today': 42,\n",
       " 'too': 43,\n",
       " 'going': 44,\n",
       " 'love': 45,\n",
       " 'work': 46,\n",
       " 'cant': 47,\n",
       " 'got': 48,\n",
       " 'time': 49,\n",
       " 'from': 50,\n",
       " 'back': 51,\n",
       " 'lol': 52,\n",
       " 'u': 53,\n",
       " 'what': 54,\n",
       " 'one': 55,\n",
       " 'will': 56,\n",
       " 'know': 57,\n",
       " 'we': 58,\n",
       " 'about': 59,\n",
       " 'really': 60,\n",
       " 'am': 61,\n",
       " 'had': 62,\n",
       " 'can': 63,\n",
       " 'see': 64,\n",
       " 'some': 65,\n",
       " 'well': 66,\n",
       " 'if': 67,\n",
       " 'still': 68,\n",
       " 'want': 69,\n",
       " 'new': 70,\n",
       " 'night': 71,\n",
       " 'how': 72,\n",
       " 'think': 73,\n",
       " 'amp': 74,\n",
       " 'thanks': 75,\n",
       " 'home': 76,\n",
       " 'as': 77,\n",
       " 'when': 78,\n",
       " 'there': 79,\n",
       " 'oh': 80,\n",
       " '2': 81,\n",
       " 'more': 82,\n",
       " 'much': 83,\n",
       " 'off': 84,\n",
       " 'miss': 85,\n",
       " 'here': 86,\n",
       " 'they': 87,\n",
       " 'need': 88,\n",
       " 'last': 89,\n",
       " 'an': 90,\n",
       " 'then': 91,\n",
       " 'been': 92,\n",
       " 'morning': 93,\n",
       " 'hope': 94,\n",
       " 'has': 95,\n",
       " 'great': 96,\n",
       " 'tomorrow': 97,\n",
       " 'ill': 98,\n",
       " 'twitter': 99,\n",
       " 'or': 100,\n",
       " 'her': 101,\n",
       " 'thats': 102,\n",
       " 'haha': 103,\n",
       " 'feel': 104,\n",
       " 'again': 105,\n",
       " 'sad': 106,\n",
       " 'he': 107,\n",
       " 'fun': 108,\n",
       " 'wish': 109,\n",
       " 'only': 110,\n",
       " 'why': 111,\n",
       " 'right': 112,\n",
       " 'didnt': 113,\n",
       " 'sleep': 114,\n",
       " 'bad': 115,\n",
       " 'would': 116,\n",
       " 'very': 117,\n",
       " 'happy': 118,\n",
       " 'sorry': 119,\n",
       " 'by': 120,\n",
       " 'did': 121,\n",
       " 'tonight': 122,\n",
       " 'come': 123,\n",
       " 'make': 124,\n",
       " 'them': 125,\n",
       " 'were': 126,\n",
       " 'getting': 127,\n",
       " 'way': 128,\n",
       " 'gonna': 129,\n",
       " 'though': 130,\n",
       " 'nice': 131,\n",
       " 'over': 132,\n",
       " 'ive': 133,\n",
       " 'better': 134,\n",
       " 'watching': 135,\n",
       " 'should': 136,\n",
       " 'she': 137,\n",
       " 'wait': 138,\n",
       " 'could': 139,\n",
       " 'yeah': 140,\n",
       " 'bed': 141,\n",
       " 'week': 142,\n",
       " 'youre': 143,\n",
       " 'people': 144,\n",
       " 'school': 145,\n",
       " 'hate': 146,\n",
       " 'him': 147,\n",
       " 'days': 148,\n",
       " 'even': 149,\n",
       " 'after': 150,\n",
       " 'hey': 151,\n",
       " 'next': 152,\n",
       " 'down': 153,\n",
       " 'weekend': 154,\n",
       " 'yes': 155,\n",
       " 'awesome': 156,\n",
       " 'never': 157,\n",
       " 'thank': 158,\n",
       " 'soon': 159,\n",
       " 'take': 160,\n",
       " 'little': 161,\n",
       " 'long': 162,\n",
       " 'first': 163,\n",
       " 'working': 164,\n",
       " 'wanna': 165,\n",
       " 'who': 166,\n",
       " 'say': 167,\n",
       " 'best': 168,\n",
       " 'please': 169,\n",
       " 'doing': 170,\n",
       " 'having': 171,\n",
       " '4': 172,\n",
       " 'being': 173,\n",
       " 'show': 174,\n",
       " 'tired': 175,\n",
       " 'sick': 176,\n",
       " 'watch': 177,\n",
       " 'everyone': 178,\n",
       " 'his': 179,\n",
       " 'ok': 180,\n",
       " 'our': 181,\n",
       " 'wont': 182,\n",
       " 'life': 183,\n",
       " 'any': 184,\n",
       " '3': 185,\n",
       " 'done': 186,\n",
       " 'feeling': 187,\n",
       " 'always': 188,\n",
       " 'sure': 189,\n",
       " 'friends': 190,\n",
       " 'already': 191,\n",
       " 'thing': 192,\n",
       " 'than': 193,\n",
       " 'another': 194,\n",
       " 'us': 195,\n",
       " 'find': 196,\n",
       " 'cool': 197,\n",
       " 'something': 198,\n",
       " 'guys': 199,\n",
       " 'ready': 200,\n",
       " 'made': 201,\n",
       " 'x': 202,\n",
       " 'where': 203,\n",
       " 'because': 204,\n",
       " 'looking': 205,\n",
       " 'yay': 206,\n",
       " 'went': 207,\n",
       " 'look': 208,\n",
       " 'man': 209,\n",
       " 'phone': 210,\n",
       " 'doesnt': 211,\n",
       " 'ur': 212,\n",
       " 'yet': 213,\n",
       " 'hours': 214,\n",
       " 'before': 215,\n",
       " 'house': 216,\n",
       " 'movie': 217,\n",
       " 'pretty': 218,\n",
       " 'ever': 219,\n",
       " 'trying': 220,\n",
       " 'away': 221,\n",
       " 'maybe': 222,\n",
       " 'omg': 223,\n",
       " 'finally': 224,\n",
       " 'old': 225,\n",
       " 'help': 226,\n",
       " 'summer': 227,\n",
       " 'let': 228,\n",
       " 'amazing': 229,\n",
       " 'early': 230,\n",
       " 'things': 231,\n",
       " 'into': 232,\n",
       " 'left': 233,\n",
       " 'lost': 234,\n",
       " 'tweet': 235,\n",
       " 'guess': 236,\n",
       " 'follow': 237,\n",
       " 'damn': 238,\n",
       " 'keep': 239,\n",
       " 'thought': 240,\n",
       " 'someone': 241,\n",
       " 'big': 242,\n",
       " 'missed': 243,\n",
       " 'bit': 244,\n",
       " 'lt3': 245,\n",
       " 'same': 246,\n",
       " 'hot': 247,\n",
       " 'havent': 248,\n",
       " 'while': 249,\n",
       " 'sucks': 250,\n",
       " 'nothing': 251,\n",
       " 'year': 252,\n",
       " 'rain': 253,\n",
       " 'start': 254,\n",
       " 'friend': 255,\n",
       " 'glad': 256,\n",
       " 'try': 257,\n",
       " 'wow': 258,\n",
       " 'other': 259,\n",
       " 'coming': 260,\n",
       " 'also': 261,\n",
       " 'tell': 262,\n",
       " 'looks': 263,\n",
       " 'birthday': 264,\n",
       " 'bored': 265,\n",
       " 'live': 266,\n",
       " 'does': 267,\n",
       " 'two': 268,\n",
       " '1': 269,\n",
       " 'hear': 270,\n",
       " 'girl': 271,\n",
       " 'later': 272,\n",
       " 'weather': 273,\n",
       " 'actually': 274,\n",
       " 'those': 275,\n",
       " 'saw': 276,\n",
       " 'baby': 277,\n",
       " 'ya': 278,\n",
       " 'sun': 279,\n",
       " 'song': 280,\n",
       " 'isnt': 281,\n",
       " 'makes': 282,\n",
       " 'stuff': 283,\n",
       " 'might': 284,\n",
       " 'excited': 285,\n",
       " 'waiting': 286,\n",
       " 'n': 287,\n",
       " 'party': 288,\n",
       " 'said': 289,\n",
       " 'hard': 290,\n",
       " 'play': 291,\n",
       " 'hes': 292,\n",
       " 'since': 293,\n",
       " 'until': 294,\n",
       " 'game': 295,\n",
       " 'few': 296,\n",
       " 'ugh': 297,\n",
       " 'such': 298,\n",
       " 'lot': 299,\n",
       " 'yesterday': 300,\n",
       " 'gotta': 301,\n",
       " 'late': 302,\n",
       " 'around': 303,\n",
       " 'god': 304,\n",
       " 'id': 305,\n",
       " 'hi': 306,\n",
       " 'myself': 307,\n",
       " 'world': 308,\n",
       " 'many': 309,\n",
       " 'car': 310,\n",
       " 'sounds': 311,\n",
       " 'found': 312,\n",
       " 'music': 313,\n",
       " 'luck': 314,\n",
       " 'check': 315,\n",
       " 'their': 316,\n",
       " 'head': 317,\n",
       " 'job': 318,\n",
       " 'give': 319,\n",
       " 'beautiful': 320,\n",
       " 'must': 321,\n",
       " 'friday': 322,\n",
       " 'read': 323,\n",
       " 'cold': 324,\n",
       " 'making': 325,\n",
       " 'call': 326,\n",
       " 'whats': 327,\n",
       " 'put': 328,\n",
       " 'gone': 329,\n",
       " 'talk': 330,\n",
       " 'may': 331,\n",
       " 'sunday': 332,\n",
       " 'missing': 333,\n",
       " 'aww': 334,\n",
       " 'least': 335,\n",
       " 'anything': 336,\n",
       " 'woke': 337,\n",
       " '5': 338,\n",
       " 'poor': 339,\n",
       " 'till': 340,\n",
       " 'mom': 341,\n",
       " 'stop': 342,\n",
       " 'monday': 343,\n",
       " 'use': 344,\n",
       " 'leave': 345,\n",
       " 'most': 346,\n",
       " 'almost': 347,\n",
       " 'times': 348,\n",
       " 'listening': 349,\n",
       " 'okay': 350,\n",
       " 'cute': 351,\n",
       " 'tho': 352,\n",
       " 'hair': 353,\n",
       " 'far': 354,\n",
       " 'wanted': 355,\n",
       " 'hurts': 356,\n",
       " 'lunch': 357,\n",
       " 'mean': 358,\n",
       " 'eat': 359,\n",
       " 'iphone': 360,\n",
       " 'free': 361,\n",
       " 'family': 362,\n",
       " 'theres': 363,\n",
       " 'enjoy': 364,\n",
       " 'funny': 365,\n",
       " 'shes': 366,\n",
       " 'food': 367,\n",
       " 'finished': 368,\n",
       " 'hour': 369,\n",
       " 'end': 370,\n",
       " 'dinner': 371,\n",
       " 'believe': 372,\n",
       " 'playing': 373,\n",
       " 'forward': 374,\n",
       " 'anyone': 375,\n",
       " 'welcome': 376,\n",
       " 'without': 377,\n",
       " 'followers': 378,\n",
       " 'thinking': 379,\n",
       " 'shit': 380,\n",
       " 'everything': 381,\n",
       " 'sweet': 382,\n",
       " 'which': 383,\n",
       " 'cause': 384,\n",
       " 'totally': 385,\n",
       " 'video': 386,\n",
       " 'these': 387,\n",
       " 'wasnt': 388,\n",
       " 'buy': 389,\n",
       " 'outside': 390,\n",
       " 'enough': 391,\n",
       " 'stupid': 392,\n",
       " 'hahaha': 393,\n",
       " 'through': 394,\n",
       " 'weeks': 395,\n",
       " 'r': 396,\n",
       " 'mine': 397,\n",
       " 'coffee': 398,\n",
       " 'wrong': 399,\n",
       " 'every': 400,\n",
       " 'real': 401,\n",
       " 'anymore': 402,\n",
       " 'probably': 403,\n",
       " 'couldnt': 404,\n",
       " 'w': 405,\n",
       " 'place': 406,\n",
       " 'once': 407,\n",
       " 'eating': 408,\n",
       " 'wants': 409,\n",
       " 'room': 410,\n",
       " 'stay': 411,\n",
       " 'tweets': 412,\n",
       " 'money': 413,\n",
       " 'xx': 414,\n",
       " 'busy': 415,\n",
       " 'sooo': 416,\n",
       " 'following': 417,\n",
       " 'tv': 418,\n",
       " 'win': 419,\n",
       " 'hell': 420,\n",
       " 'ha': 421,\n",
       " 'lovely': 422,\n",
       " 'whole': 423,\n",
       " 'came': 424,\n",
       " 'seen': 425,\n",
       " 'says': 426,\n",
       " 'taking': 427,\n",
       " 'saturday': 428,\n",
       " 'pic': 429,\n",
       " 'kinda': 430,\n",
       " 'kids': 431,\n",
       " 'class': 432,\n",
       " 'exam': 433,\n",
       " '10': 434,\n",
       " 'beach': 435,\n",
       " 'both': 436,\n",
       " 'took': 437,\n",
       " 'hopefully': 438,\n",
       " 'years': 439,\n",
       " 'crazy': 440,\n",
       " 'headache': 441,\n",
       " 'lets': 442,\n",
       " 'super': 443,\n",
       " 'name': 444,\n",
       " 'idea': 445,\n",
       " 'd': 446,\n",
       " 'hello': 447,\n",
       " 'able': 448,\n",
       " 'dad': 449,\n",
       " 'news': 450,\n",
       " 'theyre': 451,\n",
       " 'half': 452,\n",
       " 'true': 453,\n",
       " 'forgot': 454,\n",
       " 'guy': 455,\n",
       " 'book': 456,\n",
       " 'meet': 457,\n",
       " 'goodnight': 458,\n",
       " 'lots': 459,\n",
       " 'post': 460,\n",
       " 'awww': 461,\n",
       " 'leaving': 462,\n",
       " 'face': 463,\n",
       " 'sitting': 464,\n",
       " 'girls': 465,\n",
       " 'o': 466,\n",
       " 'send': 467,\n",
       " 'rest': 468,\n",
       " 'either': 469,\n",
       " 'ago': 470,\n",
       " 'used': 471,\n",
       " 'reading': 472,\n",
       " 'else': 473,\n",
       " 'full': 474,\n",
       " 'feels': 475,\n",
       " 'shopping': 476,\n",
       " 'soo': 477,\n",
       " 'hurt': 478,\n",
       " 'computer': 479,\n",
       " 'run': 480,\n",
       " 'seems': 481,\n",
       " 'ah': 482,\n",
       " 'talking': 483,\n",
       " 'cuz': 484,\n",
       " 'watched': 485,\n",
       " 'raining': 486,\n",
       " 'own': 487,\n",
       " 'tried': 488,\n",
       " 'hit': 489,\n",
       " 'remember': 490,\n",
       " 'needs': 491,\n",
       " 'stuck': 492,\n",
       " 'heard': 493,\n",
       " 'alone': 494,\n",
       " 'blog': 495,\n",
       " '6': 496,\n",
       " 'b': 497,\n",
       " 'trip': 498,\n",
       " 'fuck': 499,\n",
       " 'office': 500,\n",
       " 'boo': 501,\n",
       " 'started': 502,\n",
       " 'kind': 503,\n",
       " 'dog': 504,\n",
       " 'btw': 505,\n",
       " 'course': 506,\n",
       " 'heart': 507,\n",
       " 'seeing': 508,\n",
       " 'hehe': 509,\n",
       " 'internet': 510,\n",
       " 'part': 511,\n",
       " 'mind': 512,\n",
       " 'using': 513,\n",
       " 'quite': 514,\n",
       " 'mileycyrus': 515,\n",
       " 'online': 516,\n",
       " 'picture': 517,\n",
       " 'add': 518,\n",
       " 'told': 519,\n",
       " 'awake': 520,\n",
       " 'loved': 521,\n",
       " 'pics': 522,\n",
       " 'goes': 523,\n",
       " 'boy': 524,\n",
       " 'fine': 525,\n",
       " 'cry': 526,\n",
       " 'til': 527,\n",
       " 'pain': 528,\n",
       " 'break': 529,\n",
       " 'breakfast': 530,\n",
       " 'la': 531,\n",
       " 'change': 532,\n",
       " 'gets': 533,\n",
       " 'wake': 534,\n",
       " 's': 535,\n",
       " 'bought': 536,\n",
       " 'sunny': 537,\n",
       " 'person': 538,\n",
       " 'boring': 539,\n",
       " 'seriously': 540,\n",
       " 'broke': 541,\n",
       " 'update': 542,\n",
       " 'minutes': 543,\n",
       " 'care': 544,\n",
       " 'called': 545,\n",
       " 'facebook': 546,\n",
       " 'youll': 547,\n",
       " 'starting': 548,\n",
       " 'concert': 549,\n",
       " 'season': 550,\n",
       " 'open': 551,\n",
       " 'pay': 552,\n",
       " 'lucky': 553,\n",
       " 'asleep': 554,\n",
       " 'reply': 555,\n",
       " 'aw': 556,\n",
       " 'dude': 557,\n",
       " 'lmao': 558,\n",
       " 'ass': 559,\n",
       " 'june': 560,\n",
       " 'bring': 561,\n",
       " 'favorite': 562,\n",
       " 'link': 563,\n",
       " '8': 564,\n",
       " 'hungry': 565,\n",
       " 'crap': 566,\n",
       " 'site': 567,\n",
       " 'heading': 568,\n",
       " 'anyway': 569,\n",
       " 'instead': 570,\n",
       " 'email': 571,\n",
       " '30': 572,\n",
       " 'sleeping': 573,\n",
       " 'mothers': 574,\n",
       " 'xd': 575,\n",
       " 'walk': 576,\n",
       " 'month': 577,\n",
       " 'train': 578,\n",
       " 'study': 579,\n",
       " 'afternoon': 580,\n",
       " 'drive': 581,\n",
       " 'shower': 582,\n",
       " 'fan': 583,\n",
       " 'jealous': 584,\n",
       " 'enjoying': 585,\n",
       " 'tommcfly': 586,\n",
       " 'exams': 587,\n",
       " 'red': 588,\n",
       " 'bout': 589,\n",
       " '100': 590,\n",
       " 'text': 591,\n",
       " 'wonderful': 592,\n",
       " 'mad': 593,\n",
       " 'definitely': 594,\n",
       " 'hoping': 595,\n",
       " 'sore': 596,\n",
       " 'ice': 597,\n",
       " 'yea': 598,\n",
       " 'move': 599,\n",
       " 'soooo': 600,\n",
       " '7': 601,\n",
       " 'bye': 602,\n",
       " 'running': 603,\n",
       " 'finish': 604,\n",
       " 'together': 605,\n",
       " 'problem': 606,\n",
       " 'bday': 607,\n",
       " 'rock': 608,\n",
       " 'died': 609,\n",
       " 'congrats': 610,\n",
       " 'means': 611,\n",
       " 'ask': 612,\n",
       " 'high': 613,\n",
       " 'ones': 614,\n",
       " 'happened': 615,\n",
       " 'works': 616,\n",
       " 'fucking': 617,\n",
       " 'dead': 618,\n",
       " 'goin': 619,\n",
       " 'fail': 620,\n",
       " 'sister': 621,\n",
       " 'city': 622,\n",
       " 'sometimes': 623,\n",
       " 'homework': 624,\n",
       " 'couple': 625,\n",
       " 'write': 626,\n",
       " 'boys': 627,\n",
       " 'dear': 628,\n",
       " 'won': 629,\n",
       " 'movies': 630,\n",
       " 'album': 631,\n",
       " 'drink': 632,\n",
       " 'comes': 633,\n",
       " 'suck': 634,\n",
       " 'cut': 635,\n",
       " 'laptop': 636,\n",
       " 'loves': 637,\n",
       " 'wouldnt': 638,\n",
       " 'brother': 639,\n",
       " '12': 640,\n",
       " 'p': 641,\n",
       " 'top': 642,\n",
       " 'set': 643,\n",
       " 'months': 644,\n",
       " 'ddlovato': 645,\n",
       " 'youtube': 646,\n",
       " 'eyes': 647,\n",
       " 'tour': 648,\n",
       " 'church': 649,\n",
       " 'arent': 650,\n",
       " 'ppl': 651,\n",
       " 'ipod': 652,\n",
       " 'reason': 653,\n",
       " 'sound': 654,\n",
       " 'happen': 655,\n",
       " 'water': 656,\n",
       " 'tea': 657,\n",
       " 'evening': 658,\n",
       " 'visit': 659,\n",
       " 'perfect': 660,\n",
       " 'final': 661,\n",
       " 'songs': 662,\n",
       " 'dream': 663,\n",
       " 'lil': 664,\n",
       " 'town': 665,\n",
       " 'meeting': 666,\n",
       " 'listen': 667,\n",
       " 'studying': 668,\n",
       " 'nap': 669,\n",
       " 'weird': 670,\n",
       " 'seem': 671,\n",
       " 'fall': 672,\n",
       " 'nite': 673,\n",
       " 'yall': 674,\n",
       " 'sigh': 675,\n",
       " 'loving': 676,\n",
       " 'side': 677,\n",
       " 'dance': 678,\n",
       " 'gym': 679,\n",
       " 'tickets': 680,\n",
       " 'close': 681,\n",
       " 'test': 682,\n",
       " 'less': 683,\n",
       " 'hang': 684,\n",
       " 'english': 685,\n",
       " 'mood': 686,\n",
       " 'fb': 687,\n",
       " 'ate': 688,\n",
       " 'interesting': 689,\n",
       " 'knew': 690,\n",
       " 'catch': 691,\n",
       " 'cat': 692,\n",
       " 'agree': 693,\n",
       " 'cream': 694,\n",
       " 'second': 695,\n",
       " 'clean': 696,\n",
       " 'turn': 697,\n",
       " 'list': 698,\n",
       " 'store': 699,\n",
       " 'moment': 700,\n",
       " 'worst': 701,\n",
       " 'aint': 702,\n",
       " 'writing': 703,\n",
       " 'gt': 704,\n",
       " 'story': 705,\n",
       " 'saying': 706,\n",
       " 'awards': 707,\n",
       " 'ahh': 708,\n",
       " 'word': 709,\n",
       " 'ride': 710,\n",
       " 'supposed': 711,\n",
       " 'worth': 712,\n",
       " 'pool': 713,\n",
       " 'chocolate': 714,\n",
       " 'wishing': 715,\n",
       " 'smile': 716,\n",
       " 'broken': 717,\n",
       " 'london': 718,\n",
       " 'fast': 719,\n",
       " 'via': 720,\n",
       " 'unfortunately': 721,\n",
       " 'page': 722,\n",
       " 'moving': 723,\n",
       " 'past': 724,\n",
       " 'driving': 725,\n",
       " 'air': 726,\n",
       " '20': 727,\n",
       " 'three': 728,\n",
       " 'xxx': 729,\n",
       " '1st': 730,\n",
       " 'throat': 731,\n",
       " 'forget': 732,\n",
       " 'sent': 733,\n",
       " 'pictures': 734,\n",
       " 'gave': 735,\n",
       " 'dreams': 736,\n",
       " 'yep': 737,\n",
       " 'wedding': 738,\n",
       " 'da': 739,\n",
       " 'short': 740,\n",
       " 'understand': 741,\n",
       " 'photo': 742,\n",
       " 'park': 743,\n",
       " 'cleaning': 744,\n",
       " 'followfriday': 745,\n",
       " 'sunshine': 746,\n",
       " 'horrible': 747,\n",
       " 'black': 748,\n",
       " 'sleepy': 749,\n",
       " 'drinking': 750,\n",
       " 'pick': 751,\n",
       " 'jonas': 752,\n",
       " 'plan': 753,\n",
       " 'tweeting': 754,\n",
       " 'chance': 755,\n",
       " 'college': 756,\n",
       " 'account': 757,\n",
       " 'star': 758,\n",
       " 'wonder': 759,\n",
       " 'worse': 760,\n",
       " 'rather': 761,\n",
       " 'under': 762,\n",
       " 'longer': 763,\n",
       " 'fell': 764,\n",
       " 'slow': 765,\n",
       " 'em': 766,\n",
       " 'team': 767,\n",
       " 'vote': 768,\n",
       " 'hugs': 769,\n",
       " 'hmm': 770,\n",
       " 'sat': 771,\n",
       " 'cannot': 772,\n",
       " 'scared': 773,\n",
       " 'bet': 774,\n",
       " 'easy': 775,\n",
       " 'apparently': 776,\n",
       " 'parents': 777,\n",
       " 'date': 778,\n",
       " 'youve': 779,\n",
       " 'upset': 780,\n",
       " 'due': 781,\n",
       " 'moon': 782,\n",
       " 'spent': 783,\n",
       " 'flight': 784,\n",
       " 'green': 785,\n",
       " 'point': 786,\n",
       " 'lady': 787,\n",
       " 'mac': 788,\n",
       " 'special': 789,\n",
       " 'huge': 790,\n",
       " 'holiday': 791,\n",
       " 'updates': 792,\n",
       " 'mtv': 793,\n",
       " 'plans': 794,\n",
       " 'mum': 795,\n",
       " 'spend': 796,\n",
       " 'hows': 797,\n",
       " 'tuesday': 798,\n",
       " 'hanging': 799,\n",
       " 'hand': 800,\n",
       " 'flu': 801,\n",
       " '9': 802,\n",
       " 'plus': 803,\n",
       " 'fair': 804,\n",
       " 'nope': 805,\n",
       " 'earlier': 806,\n",
       " 'join': 807,\n",
       " 'c': 808,\n",
       " 'thx': 809,\n",
       " 'wondering': 810,\n",
       " 'wtf': 811,\n",
       " 'words': 812,\n",
       " 'shows': 813,\n",
       " 'band': 814,\n",
       " 'miley': 815,\n",
       " 'during': 816,\n",
       " 'ps': 817,\n",
       " 'shame': 818,\n",
       " 'website': 819,\n",
       " 'worry': 820,\n",
       " 'lazy': 821,\n",
       " 'body': 822,\n",
       " 'bus': 823,\n",
       " 'message': 824,\n",
       " 'slept': 825,\n",
       " 'y': 826,\n",
       " 'wear': 827,\n",
       " 'uk': 828,\n",
       " 'brothers': 829,\n",
       " 'answer': 830,\n",
       " 'forever': 831,\n",
       " 'thinks': 832,\n",
       " 'vacation': 833,\n",
       " 'white': 834,\n",
       " 'stomach': 835,\n",
       " 'ahhh': 836,\n",
       " 'warm': 837,\n",
       " 'beer': 838,\n",
       " 'looked': 839,\n",
       " 'mr': 840,\n",
       " 'jonasbrothers': 841,\n",
       " 'figure': 842,\n",
       " 'learn': 843,\n",
       " 'voice': 844,\n",
       " 'thursday': 845,\n",
       " 'sadly': 846,\n",
       " 'idk': 847,\n",
       " 'especially': 848,\n",
       " 'different': 849,\n",
       " 'support': 850,\n",
       " 'fans': 851,\n",
       " 'july': 852,\n",
       " 'die': 853,\n",
       " 'cake': 854,\n",
       " 'meant': 855,\n",
       " '15': 856,\n",
       " 'line': 857,\n",
       " 'sims': 858,\n",
       " 'inside': 859,\n",
       " 'chat': 860,\n",
       " 'google': 861,\n",
       " 'met': 862,\n",
       " 'itll': 863,\n",
       " 'photos': 864,\n",
       " 'liked': 865,\n",
       " 'number': 866,\n",
       " 'myspace': 867,\n",
       " 'officially': 868,\n",
       " 'episode': 869,\n",
       " 'fix': 870,\n",
       " 'safe': 871,\n",
       " 'rainy': 872,\n",
       " 'david': 873,\n",
       " 'camera': 874,\n",
       " 'airport': 875,\n",
       " 'crying': 876,\n",
       " 'dress': 877,\n",
       " 'small': 878,\n",
       " 'pizza': 879,\n",
       " 'absolutely': 880,\n",
       " 'yummy': 881,\n",
       " 'bbq': 882,\n",
       " 'tom': 883,\n",
       " 'shop': 884,\n",
       " 'tummy': 885,\n",
       " 'games': 886,\n",
       " 'shall': 887,\n",
       " 'worked': 888,\n",
       " 'felt': 889,\n",
       " 'decided': 890,\n",
       " 'luv': 891,\n",
       " 'paper': 892,\n",
       " 'proud': 893,\n",
       " 'rip': 894,\n",
       " 'boyfriend': 895,\n",
       " 'graduation': 896,\n",
       " 'each': 897,\n",
       " 'power': 898,\n",
       " 'garden': 899,\n",
       " 'finals': 900,\n",
       " 'project': 901,\n",
       " 'save': 902,\n",
       " 'except': 903,\n",
       " 'shoes': 904,\n",
       " 'needed': 905,\n",
       " 'beat': 906,\n",
       " 'eye': 907,\n",
       " '2day': 908,\n",
       " 'wit': 909,\n",
       " 'yourself': 910,\n",
       " 'kill': 911,\n",
       " 'bike': 912,\n",
       " 'radio': 913,\n",
       " 'played': 914,\n",
       " 'road': 915,\n",
       " 'hug': 916,\n",
       " 'gorgeous': 917,\n",
       " 'lonely': 918,\n",
       " 'starts': 919,\n",
       " 'keeps': 920,\n",
       " 'nights': 921,\n",
       " 'annoying': 922,\n",
       " 'blue': 923,\n",
       " 'books': 924,\n",
       " 'apple': 925,\n",
       " 'chicken': 926,\n",
       " 'exactly': 927,\n",
       " 'hospital': 928,\n",
       " 'alright': 929,\n",
       " 'case': 930,\n",
       " 'wishes': 931,\n",
       " 'exciting': 932,\n",
       " 'cos': 933,\n",
       " 'sign': 934,\n",
       " 'kid': 935,\n",
       " 'hates': 936,\n",
       " 'yup': 937,\n",
       " 'front': 938,\n",
       " 'card': 939,\n",
       " 'taken': 940,\n",
       " 'twilight': 941,\n",
       " 'feet': 942,\n",
       " 'french': 943,\n",
       " 'living': 944,\n",
       " 'son': 945,\n",
       " 'wine': 946,\n",
       " 'fact': 947,\n",
       " 'wednesday': 948,\n",
       " 'dm': 949,\n",
       " 'xoxo': 950,\n",
       " 'near': 951,\n",
       " 'babe': 952,\n",
       " 'lame': 953,\n",
       " 'turned': 954,\n",
       " 'packing': 955,\n",
       " 'woo': 956,\n",
       " 'cd': 957,\n",
       " 'laugh': 958,\n",
       " 'knows': 959,\n",
       " 'goodbye': 960,\n",
       " 'pink': 961,\n",
       " 'realized': 962,\n",
       " '2nd': 963,\n",
       " 'hubby': 964,\n",
       " 'scary': 965,\n",
       " 'happens': 966,\n",
       " 'share': 967,\n",
       " 'club': 968,\n",
       " 'behind': 969,\n",
       " 'question': 970,\n",
       " 'bc': 971,\n",
       " 'sold': 972,\n",
       " 'ouch': 973,\n",
       " 'jus': 974,\n",
       " 'download': 975,\n",
       " 'waking': 976,\n",
       " 'business': 977,\n",
       " 'gettin': 978,\n",
       " 'pass': 979,\n",
       " 'cup': 980,\n",
       " 'yours': 981,\n",
       " 'moms': 982,\n",
       " 'service': 983,\n",
       " 'giving': 984,\n",
       " 'killing': 985,\n",
       " 'videos': 986,\n",
       " 'lose': 987,\n",
       " 'walking': 988,\n",
       " 'yo': 989,\n",
       " 'drunk': 990,\n",
       " 'minute': 991,\n",
       " 'clothes': 992,\n",
       " 'order': 993,\n",
       " 'although': 994,\n",
       " 'app': 995,\n",
       " 'along': 996,\n",
       " 'enjoyed': 997,\n",
       " 'relaxing': 998,\n",
       " 'hahah': 999,\n",
       " 'terrible': 1000,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Enumerated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to encode the reviews themselves, this function will apply 0s if we encounter a word we haven't got, which we shouldn't and the enumeration of the word otherwise.\n",
    "\n",
    "def Encode(tweet):\n",
    "    \n",
    "    encoded_tweet = []\n",
    "    \n",
    "    for word in tweet:\n",
    "        if word not in Enumerated_words:\n",
    "            encoded_tweet.append(0)\n",
    "            \n",
    "        else:\n",
    "            encoded_tweet.append(Enumerated_words[word])\n",
    "    return encoded_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_words</th>\n",
       "      <th>Tweets_counted</th>\n",
       "      <th>Encoded_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>{'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...</td>\n",
       "      <td>[20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>{'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...</td>\n",
       "      <td>[8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>[kenichan, i, dived, many, times, for, the, ba...</td>\n",
       "      <td>{'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...</td>\n",
       "      <td>[28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>{'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...</td>\n",
       "      <td>[5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>{'nationwideclass': 1, 'no': 1, 'its': 1, 'not...</td>\n",
       "      <td>[36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                         Tweet_text  \\\n",
       "0          0  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1          0  is upset that he cant update his facebook by t...   \n",
       "2          0  kenichan i dived many times for the ball manag...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  nationwideclass no its not behaving at all im ...   \n",
       "\n",
       "                                         Tweet_words  \\\n",
       "0  [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1  [is, upset, that, he, cant, update, his, faceb...   \n",
       "2  [kenichan, i, dived, many, times, for, the, ba...   \n",
       "3  [my, whole, body, feels, itchy, and, like, its...   \n",
       "4  [nationwideclass, no, its, not, behaving, at, ...   \n",
       "\n",
       "                                      Tweets_counted  \\\n",
       "0  {'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...   \n",
       "1  {'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...   \n",
       "2  {'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...   \n",
       "3  {'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...   \n",
       "4  {'nationwideclass': 1, 'no': 1, 'its': 1, 'not...   \n",
       "\n",
       "                                       Encoded_Tweet  \n",
       "0  [20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...  \n",
       "1  [8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...  \n",
       "2  [28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...  \n",
       "3      [5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]  \n",
       "4  [36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying the encoding to the tweets in the dataframe\n",
    "\n",
    "df['Encoded_Tweet'] = df['Tweet_words'].apply(lambda x: Encode(x))\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving because we don't want to loose this progress\n",
    "\n",
    "df.to_csv('../Sentiment_Analysis_Strategy/encoded_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../Sentiment_Analysis_Strategy/encoded_tweets.csv', header= 0, index_col=0,encoding='latin-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_words</th>\n",
       "      <th>Tweets_counted</th>\n",
       "      <th>Encoded_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>{'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...</td>\n",
       "      <td>[20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>{'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...</td>\n",
       "      <td>[8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>[kenichan, i, dived, many, times, for, the, ba...</td>\n",
       "      <td>{'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...</td>\n",
       "      <td>[28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>{'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...</td>\n",
       "      <td>[5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>{'nationwideclass': 1, 'no': 1, 'its': 1, 'not...</td>\n",
       "      <td>[36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>[just, woke, up, having, no, school, is, the, ...</td>\n",
       "      <td>{'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...</td>\n",
       "      <td>[20, 337, 30, 171, 37, 145, 8, 3, 168, 187, 219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom  very cool to hear old walt intervie...</td>\n",
       "      <td>[thewdbcom, very, cool, to, hear, old, walt, i...</td>\n",
       "      <td>{'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...</td>\n",
       "      <td>[850168, 117, 197, 2, 270, 225, 14734, 4088, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>[are, you, ready, for, your, mojo, makeover, a...</td>\n",
       "      <td>{'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...</td>\n",
       "      <td>[36, 7, 200, 10, 41, 8309, 8453, 612, 15, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
       "      <td>[happy, 38th, birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>{'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...</td>\n",
       "      <td>[118, 28296, 264, 2, 5, 501, 12, 5134, 49, 139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
       "      <td>[happy, charitytuesday, thenspcc, sparkscharit...</td>\n",
       "      <td>{'happy': 1, 'charitytuesday': 1, 'thenspcc': ...</td>\n",
       "      <td>[118, 19543, 251562, 850170, 850171]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                         Tweet_text  \\\n",
       "0                0  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1                0  is upset that he cant update his facebook by t...   \n",
       "2                0  kenichan i dived many times for the ball manag...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  nationwideclass no its not behaving at all im ...   \n",
       "...            ...                                                ...   \n",
       "1599995          4  just woke up having no school is the best feel...   \n",
       "1599996          4  thewdbcom  very cool to hear old walt intervie...   \n",
       "1599997          4  are you ready for your mojo makeover ask me fo...   \n",
       "1599998          4  happy 38th birthday to my boo of alll time tup...   \n",
       "1599999          4  happy charitytuesday thenspcc sparkscharity sp...   \n",
       "\n",
       "                                               Tweet_words  \\\n",
       "0        [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1        [is, upset, that, he, cant, update, his, faceb...   \n",
       "2        [kenichan, i, dived, many, times, for, the, ba...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [nationwideclass, no, its, not, behaving, at, ...   \n",
       "...                                                    ...   \n",
       "1599995  [just, woke, up, having, no, school, is, the, ...   \n",
       "1599996  [thewdbcom, very, cool, to, hear, old, walt, i...   \n",
       "1599997  [are, you, ready, for, your, mojo, makeover, a...   \n",
       "1599998  [happy, 38th, birthday, to, my, boo, of, alll,...   \n",
       "1599999  [happy, charitytuesday, thenspcc, sparkscharit...   \n",
       "\n",
       "                                            Tweets_counted  \\\n",
       "0        {'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...   \n",
       "1        {'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...   \n",
       "2        {'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...   \n",
       "3        {'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...   \n",
       "4        {'nationwideclass': 1, 'no': 1, 'its': 1, 'not...   \n",
       "...                                                    ...   \n",
       "1599995  {'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...   \n",
       "1599996  {'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...   \n",
       "1599997  {'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...   \n",
       "1599998  {'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...   \n",
       "1599999  {'happy': 1, 'charitytuesday': 1, 'thenspcc': ...   \n",
       "\n",
       "                                             Encoded_Tweet  \n",
       "0        [20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...  \n",
       "1        [8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...  \n",
       "2        [28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...  \n",
       "3            [5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]  \n",
       "4        [36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...  \n",
       "...                                                    ...  \n",
       "1599995   [20, 337, 30, 171, 37, 145, 8, 3, 168, 187, 219]  \n",
       "1599996  [850168, 117, 197, 2, 270, 225, 14734, 4088, 1...  \n",
       "1599997  [36, 7, 200, 10, 41, 8309, 8453, 612, 15, 10, ...  \n",
       "1599998  [118, 28296, 264, 2, 5, 501, 12, 5134, 49, 139...  \n",
       "1599999               [118, 19543, 251562, 850170, 850171]  \n",
       "\n",
       "[1600000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Encoded_Tweet'].iloc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to pad out the encoding with 0s so that each of the encoding is the same length.\n",
    "\n",
    "# We will make the maximum length 280 because that is the maximum number of charachters in a tweet.\n",
    "\n",
    "sequence_length = 280\n",
    "\n",
    "# we will do this with another function that we will broadcast to the pandas dataframe, to avoid looping through \n",
    "\n",
    "def addzeros(Encoded_tweet):\n",
    "    if len(Encoded_tweet)<sequence_length:\n",
    "        tweet = list(np.zeros( sequence_length - len(Encoded_tweet))) + Encoded_tweet\n",
    "    # No tweet should be longer but this in just incase there is some other error such that a longer tweet is outputted. \n",
    "    else:\n",
    "        tweet = Encoded_tweet[:sequence_length]\n",
    "    return tweet\n",
    "\n",
    "df['Encoded_tweet_with_zeros'] = df['Encoded_Tweet'].apply(lambda x : addzeros(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Tweet_words</th>\n",
       "      <th>Tweets_counted</th>\n",
       "      <th>Encoded_Tweet</th>\n",
       "      <th>Encoded_tweet_with_zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "      <td>{'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...</td>\n",
       "      <td>[20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "      <td>{'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...</td>\n",
       "      <td>[8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>[kenichan, i, dived, many, times, for, the, ba...</td>\n",
       "      <td>{'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...</td>\n",
       "      <td>[28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>{'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...</td>\n",
       "      <td>[5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>{'nationwideclass': 1, 'no': 1, 'its': 1, 'not...</td>\n",
       "      <td>[36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>[just, woke, up, having, no, school, is, the, ...</td>\n",
       "      <td>{'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...</td>\n",
       "      <td>[20, 337, 30, 171, 37, 145, 8, 3, 168, 187, 219]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom  very cool to hear old walt intervie...</td>\n",
       "      <td>[thewdbcom, very, cool, to, hear, old, walt, i...</td>\n",
       "      <td>{'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...</td>\n",
       "      <td>[850168, 117, 197, 2, 270, 225, 14734, 4088, 1...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>[are, you, ready, for, your, mojo, makeover, a...</td>\n",
       "      <td>{'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...</td>\n",
       "      <td>[36, 7, 200, 10, 41, 8309, 8453, 612, 15, 10, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
       "      <td>[happy, 38th, birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>{'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...</td>\n",
       "      <td>[118, 28296, 264, 2, 5, 501, 12, 5134, 49, 139...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
       "      <td>[happy, charitytuesday, thenspcc, sparkscharit...</td>\n",
       "      <td>{'happy': 1, 'charitytuesday': 1, 'thenspcc': ...</td>\n",
       "      <td>[118, 19543, 251562, 850170, 850171]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                         Tweet_text  \\\n",
       "0                0  switchfoot httptwitpiccom2y1zl  awww thats a b...   \n",
       "1                0  is upset that he cant update his facebook by t...   \n",
       "2                0  kenichan i dived many times for the ball manag...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  nationwideclass no its not behaving at all im ...   \n",
       "...            ...                                                ...   \n",
       "1599995          4  just woke up having no school is the best feel...   \n",
       "1599996          4  thewdbcom  very cool to hear old walt intervie...   \n",
       "1599997          4  are you ready for your mojo makeover ask me fo...   \n",
       "1599998          4  happy 38th birthday to my boo of alll time tup...   \n",
       "1599999          4  happy charitytuesday thenspcc sparkscharity sp...   \n",
       "\n",
       "                                               Tweet_words  \\\n",
       "0        [switchfoot, httptwitpiccom2y1zl, awww, thats,...   \n",
       "1        [is, upset, that, he, cant, update, his, faceb...   \n",
       "2        [kenichan, i, dived, many, times, for, the, ba...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [nationwideclass, no, its, not, behaving, at, ...   \n",
       "...                                                    ...   \n",
       "1599995  [just, woke, up, having, no, school, is, the, ...   \n",
       "1599996  [thewdbcom, very, cool, to, hear, old, walt, i...   \n",
       "1599997  [are, you, ready, for, your, mojo, makeover, a...   \n",
       "1599998  [happy, 38th, birthday, to, my, boo, of, alll,...   \n",
       "1599999  [happy, charitytuesday, thenspcc, sparkscharit...   \n",
       "\n",
       "                                            Tweets_counted  \\\n",
       "0        {'switchfoot': 1, 'httptwitpiccom2y1zl': 1, 'a...   \n",
       "1        {'is': 1, 'upset': 1, 'that': 1, 'he': 1, 'can...   \n",
       "2        {'kenichan': 1, 'i': 1, 'dived': 1, 'many': 1,...   \n",
       "3        {'my': 1, 'whole': 1, 'body': 1, 'feels': 1, '...   \n",
       "4        {'nationwideclass': 1, 'no': 1, 'its': 1, 'not...   \n",
       "...                                                    ...   \n",
       "1599995  {'just': 1, 'woke': 1, 'up': 1, 'having': 1, '...   \n",
       "1599996  {'thewdbcom': 1, 'very': 1, 'cool': 1, 'to': 1...   \n",
       "1599997  {'are': 1, 'you': 1, 'ready': 1, 'for': 2, 'yo...   \n",
       "1599998  {'happy': 1, '38th': 1, 'birthday': 1, 'to': 1...   \n",
       "1599999  {'happy': 1, 'charitytuesday': 1, 'thenspcc': ...   \n",
       "\n",
       "                                             Encoded_Tweet  \\\n",
       "0        [20176, 254586, 461, 102, 4, 1216, 7, 3539, 48...   \n",
       "1        [8, 780, 18, 107, 47, 542, 179, 546, 120, 2047...   \n",
       "2        [28048, 1, 110468, 309, 348, 10, 3, 1352, 1649...   \n",
       "3            [5, 423, 822, 475, 2955, 6, 35, 24, 14, 1173]   \n",
       "4        [36517, 37, 24, 25, 10891, 23, 33, 13, 593, 11...   \n",
       "...                                                    ...   \n",
       "1599995   [20, 337, 30, 171, 37, 145, 8, 3, 168, 187, 219]   \n",
       "1599996  [850168, 117, 197, 2, 270, 225, 14734, 4088, 1...   \n",
       "1599997  [36, 7, 200, 10, 41, 8309, 8453, 612, 15, 10, ...   \n",
       "1599998  [118, 28296, 264, 2, 5, 501, 12, 5134, 49, 139...   \n",
       "1599999               [118, 19543, 251562, 850170, 850171]   \n",
       "\n",
       "                                  Encoded_tweet_with_zeros  \n",
       "0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                    ...  \n",
       "1599995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1599996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1599997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1599998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1599999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
